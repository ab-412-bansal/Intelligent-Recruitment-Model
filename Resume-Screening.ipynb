{"cells":[{"cell_type":"markdown","metadata":{"id":"OOo7duOvdWSz"},"source":["# ***Resume Screening : The HR solution***"]},{"cell_type":"markdown","metadata":{"id":"-GU34zNNdWE-"},"source":["## **Essence of Resume Screening :**\n","\n","* **It is the process of determining whether a candidate is qualified for a role based his or her education, experience, and other information captured on their resume.**\n","\n","* **It is a crucial yet challenging part of the hiring process.**\n","\n","* **On average, a recruiter spends 23 hours screening resumes for a single hire.**\n","\n","* **Even with automated processes, it is still the most time-consuming part of recruiting.**\n","\n","* ***Save your time (Having a defined process will) :- Make the process more efficient and more accurate Find unqualified applicants quickly Result in a shortlist of candidates to interview who are aligned to the qualifications you’re looking for This process will help you achieve your goal, to hire the most qualified and best-fitting applicant for the position.***"]},{"cell_type":"markdown","metadata":{"id":"Q4B4pEi4Cy_E"},"source":["## **Problem Statement : -**\n","\n","***Companies often receive thousands of resumes for each job posting and employ dedicated screening officers to screen qualified candidates.***\n","\n","***Hiring the right talent is a challenge for all businesses. This challenge is magnified by the high volume of applicants if the business is labor-intensive, growing, and facing high attrition rates.***\n","\n","***IT departments are short of growing markets. In a typical service organization, professionals with a variety of technical skills and business domain expertise are hired and assigned to projects to resolve customer issues. This task of selecting the best talent among many others is known as Resume Screening.***\n","\n","***Typically, large companies do not have enough time to open each CV, so they use machine learning algorithms for the Resume Screening task.***"]},{"cell_type":"markdown","metadata":{"id":"AWJA8QOq6cLC"},"source":["## **Import Libraries**"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2022-07-03T07:36:26.450245Z","iopub.status.busy":"2022-07-03T07:36:26.449642Z","iopub.status.idle":"2022-07-03T07:36:29.084022Z","shell.execute_reply":"2022-07-03T07:36:29.082502Z","shell.execute_reply.started":"2022-07-03T07:36:26.450125Z"},"id":"gapCiMwwCxpD","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import pandas as pd\n","import plotly.express as px\n","import re\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","import string\n","from nltk.corpus import stopwords"]},{"cell_type":"markdown","metadata":{"id":"MVhWQvB76lZ4"},"source":["## **Read the table**"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2022-07-03T07:36:34.617999Z","iopub.status.busy":"2022-07-03T07:36:34.617534Z","iopub.status.idle":"2022-07-03T07:36:34.712973Z","shell.execute_reply":"2022-07-03T07:36:34.711880Z","shell.execute_reply.started":"2022-07-03T07:36:34.617961Z"},"id":"Nv6sD5jvEnds","outputId":"5e8fa6f4-4f5e-49aa-e7ef-6bb4801fc1dc","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Category</th>\n","      <th>Resume</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Data Science</td>\n","      <td>Skills * Programming Languages: Python (pandas...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Data Science</td>\n","      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Data Science</td>\n","      <td>Areas of Interest Deep Learning, Control Syste...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Data Science</td>\n","      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Data Science</td>\n","      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Category                                             Resume\n","0  Data Science  Skills * Programming Languages: Python (pandas...\n","1  Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n","2  Data Science  Areas of Interest Deep Learning, Control Syste...\n","3  Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n","4  Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab..."]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('data\\\\UpdatedResumeDataSet.csv')\n","\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"s7a0rSdO6p1R"},"source":["## **Checking the length of the table**"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2022-07-03T07:36:41.360218Z","iopub.status.busy":"2022-07-03T07:36:41.359666Z","iopub.status.idle":"2022-07-03T07:36:41.368636Z","shell.execute_reply":"2022-07-03T07:36:41.367562Z","shell.execute_reply.started":"2022-07-03T07:36:41.360161Z"},"id":"lq9ibn56Ex2h","outputId":"9bb45d64-1e36-496a-824a-f879d70fa421","trusted":true},"outputs":[{"data":{"text/plain":["(962, 2)"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"markdown","metadata":{},"source":["***There are 962 observations we have in the data. Each observation represents the complete details of each candidate so we have 962 resumes for screening.***"]},{"cell_type":"markdown","metadata":{"id":"CbXjV9JNUYIz"},"source":["## **Checking the info for the columns**"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2022-07-03T07:37:14.099581Z","iopub.status.busy":"2022-07-03T07:37:14.099127Z","iopub.status.idle":"2022-07-03T07:37:14.127459Z","shell.execute_reply":"2022-07-03T07:37:14.126546Z","shell.execute_reply.started":"2022-07-03T07:37:14.099546Z"},"id":"SuqiSi5IE3Y1","outputId":"22761b79-8ba8-4869-b657-d71b9e2f2a4b","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 962 entries, 0 to 961\n","Data columns (total 2 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   Category  962 non-null    object\n"," 1   Resume    962 non-null    object\n","dtypes: object(2)\n","memory usage: 15.2+ KB\n"]}],"source":["df.info()"]},{"cell_type":"markdown","metadata":{"id":"D0qi1NHHUka7"},"source":["## **Let's check the missing values**"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2022-07-03T07:37:18.512535Z","iopub.status.busy":"2022-07-03T07:37:18.512092Z","iopub.status.idle":"2022-07-03T07:37:18.522556Z","shell.execute_reply":"2022-07-03T07:37:18.521283Z","shell.execute_reply.started":"2022-07-03T07:37:18.512499Z"},"id":"42ceHKZxPogf","outputId":"c4f61bf4-12ed-4ff3-dbc0-0994d7a68df9","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Category    0\n","Resume      0\n","dtype: int64\n"]}],"source":["print(df.isnull().sum())\n","df.drop_duplicates(subset=\"Resume\", keep='first', inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"dFsT9_MQUwZk"},"source":["## **Visualization : Category (Jobs)**"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2022-07-03T07:37:25.372003Z","iopub.status.busy":"2022-07-03T07:37:25.369996Z","iopub.status.idle":"2022-07-03T07:37:26.574517Z","shell.execute_reply":"2022-07-03T07:37:26.573220Z","shell.execute_reply.started":"2022-07-03T07:37:25.371957Z"},"id":"-AM_mK3vGMDn","outputId":"3925256d-6804-4cad-b0b5-478aa56b7f13","trusted":true},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","bingroup":"x","hovertemplate":"Category=%{x}<br>count=%{y}<extra></extra>","legendgroup":"","marker":{"color":"#636efa","pattern":{"shape":""}},"name":"","offsetgroup":"","orientation":"v","showlegend":false,"type":"histogram","x":["Data Science","Data Science","Data Science","Data Science","Data Science","Data Science","Data Science","Data Science","Data Science","Data Science","HR","HR","HR","HR","HR","HR","HR","HR","HR","HR","Advocate","Advocate","Advocate","Advocate","Advocate","Advocate","Advocate","Advocate","Advocate","Advocate","Arts","Arts","Arts","Arts","Arts","Arts","Web Designing","Web Designing","Web Designing","Web Designing","Mechanical Engineer","Mechanical Engineer","Mechanical Engineer","Mechanical Engineer","Mechanical Engineer","Sales","Sales","Sales","Sales","Sales","Health and fitness","Health and fitness","Health and fitness","Health and fitness","Health and fitness","Health and fitness","Civil Engineer","Civil Engineer","Civil Engineer","Civil Engineer","Civil Engineer","Civil Engineer","Java Developer","Java Developer","Java Developer","Java Developer","Java Developer","Java Developer","Java Developer","Java Developer","Java Developer","Java Developer","Java Developer","Java Developer","Java Developer","Business Analyst","Business Analyst","Business Analyst","Business Analyst","Business Analyst","Business Analyst","SAP Developer","SAP Developer","SAP Developer","SAP Developer","SAP Developer","SAP Developer","Automation Testing","Automation Testing","Automation Testing","Automation Testing","Automation Testing","Automation Testing","Automation Testing","Electrical Engineering","Electrical Engineering","Electrical Engineering","Electrical Engineering","Electrical Engineering","Operations Manager","Operations Manager","Operations Manager","Operations Manager","Python Developer","Python Developer","Python Developer","Python Developer","Python Developer","Python Developer","DevOps Engineer","DevOps Engineer","DevOps Engineer","DevOps Engineer","DevOps Engineer","DevOps Engineer","DevOps Engineer","Network Security Engineer","Network Security Engineer","Network Security Engineer","Network Security Engineer","Network Security Engineer","PMO","PMO","PMO","Database","Database","Database","Database","Database","Database","Database","Database","Database","Database","Database","Hadoop","Hadoop","Hadoop","Hadoop","Hadoop","Hadoop","Hadoop","ETL Developer","ETL Developer","ETL Developer","ETL Developer","ETL Developer","DotNet Developer","DotNet Developer","DotNet Developer","DotNet Developer","DotNet Developer","DotNet Developer","DotNet Developer","Blockchain","Blockchain","Blockchain","Blockchain","Blockchain","Testing","Testing","Testing","Testing","Testing","Testing","Testing"],"xaxis":"x","yaxis":"y"}],"layout":{"barmode":"relative","legend":{"tracegroupgap":0},"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}},"title":{"text":"Distribution of Job Categories"},"xaxis":{"anchor":"y","categoryarray":["Java Developer","Database","Data Science","Advocate","HR","DotNet Developer","Hadoop","DevOps Engineer","Automation Testing","Testing","Civil Engineer","Business Analyst","SAP Developer","Health and fitness","Python Developer","Arts","Electrical Engineering","Sales","Network Security Engineer","Mechanical Engineer","ETL Developer","Blockchain","Operations Manager","Web Designing","PMO"],"categoryorder":"array","domain":[0,1],"title":{"text":"Category"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"count"}}}}},"metadata":{},"output_type":"display_data"}],"source":["\n","\n","fig = px.histogram(df, x=\"Category\", title=\"Distribution of Job Categories\", category_orders={\"Category\": df[\"Category\"].value_counts().index})\n","\n","fig"]},{"cell_type":"markdown","metadata":{},"source":["**Jobs Distribution : - From the above bar chart we can see that there are 25 different categories we have in the data.**\n","\n","**The top 3 job categories we have in the data are as follows.**\n","\n","***Java developer, Testing, and DevOps Engineer.***"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2022-07-03T07:37:34.885191Z","iopub.status.busy":"2022-07-03T07:37:34.884824Z","iopub.status.idle":"2022-07-03T07:37:34.895073Z","shell.execute_reply":"2022-07-03T07:37:34.894291Z","shell.execute_reply.started":"2022-07-03T07:37:34.885160Z"},"id":"W9HZSvvULFat","outputId":"1e82c5a9-c116-404b-8432-10ac468c316c","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                     Category  Total\n","0              Java Developer     13\n","1                    Database     11\n","2                Data Science     10\n","3                    Advocate     10\n","4                          HR     10\n","5            DotNet Developer      7\n","6                      Hadoop      7\n","7             DevOps Engineer      7\n","8          Automation Testing      7\n","9                     Testing      7\n","10             Civil Engineer      6\n","11           Business Analyst      6\n","12              SAP Developer      6\n","13         Health and fitness      6\n","14           Python Developer      6\n","15                       Arts      6\n","16     Electrical Engineering      5\n","17                      Sales      5\n","18  Network Security Engineer      5\n","19        Mechanical Engineer      5\n","20              ETL Developer      5\n","21                 Blockchain      5\n","22         Operations Manager      4\n","23              Web Designing      4\n","24                        PMO      3\n"]}],"source":["series = df['Category'].value_counts()\n","\n","df_result = pd.DataFrame(series)\n","\n","df_result = df_result.reset_index()  \n","\n","df_result.columns = ['Category', 'Total']\n","\n","print(df_result)"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2022-07-03T07:37:40.649119Z","iopub.status.busy":"2022-07-03T07:37:40.648729Z","iopub.status.idle":"2022-07-03T07:37:40.657098Z","shell.execute_reply":"2022-07-03T07:37:40.655870Z","shell.execute_reply.started":"2022-07-03T07:37:40.649084Z"},"id":"75PKZzmLOkjU","outputId":"f8f49856-9f09-44ed-df34-557bd0da3028","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                     Category  Total\n","0              Java Developer     13\n","1                    Database     11\n","2                Data Science     10\n","3                    Advocate     10\n","4                          HR     10\n","5            DotNet Developer      7\n","6                      Hadoop      7\n","7             DevOps Engineer      7\n","8          Automation Testing      7\n","9                     Testing      7\n","10             Civil Engineer      6\n","11           Business Analyst      6\n","12              SAP Developer      6\n","13         Health and fitness      6\n","14           Python Developer      6\n","15                       Arts      6\n","16     Electrical Engineering      5\n","17                      Sales      5\n","18  Network Security Engineer      5\n","19        Mechanical Engineer      5\n","20              ETL Developer      5\n"]}],"source":["df_result_part = df_result.head(21)\n","print(df_result_part)"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2022-07-03T07:37:45.873223Z","iopub.status.busy":"2022-07-03T07:37:45.872745Z","iopub.status.idle":"2022-07-03T07:37:45.942605Z","shell.execute_reply":"2022-07-03T07:37:45.941618Z","shell.execute_reply.started":"2022-07-03T07:37:45.873180Z"},"id":"xm40tkNBOtJM","outputId":"2162b851-3995-4f0c-dbb8-db20eca5a052","trusted":true},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"domain":{"x":[0,1],"y":[0,1]},"hovertemplate":"Category=%{label}<br>Total=%{value}<extra></extra>","labels":["Java Developer","Database","Data Science","Advocate","HR","DotNet Developer","Hadoop","DevOps Engineer","Automation Testing","Testing","Civil Engineer","Business Analyst","SAP Developer","Health and fitness","Python Developer","Arts","Electrical Engineering","Sales","Network Security Engineer","Mechanical Engineer","ETL Developer"],"legendgroup":"","name":"","showlegend":true,"type":"pie","values":[13,11,10,10,10,7,7,7,7,7,6,6,6,6,6,6,5,5,5,5,5]}],"layout":{"legend":{"tracegroupgap":0},"margin":{"t":60},"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}}}}},"metadata":{},"output_type":"display_data"}],"source":["fig = px.pie(df_result_part,\n","                 values='Total',\n","                 names='Category')\n","\n","fig"]},{"cell_type":"markdown","metadata":{},"source":["***From the above pie chart, Instead of the count or frequency, we can also visualize the distribution of job categories in percentage***"]},{"cell_type":"markdown","metadata":{},"source":["## **Data Preprocessing**\n","\n","\n","### **we remove any unnecessary information from resumes like URLs, hashtags, and special characters. Thats why we will create Clean the ‘Resume’ column**"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2022-07-03T07:37:53.969204Z","iopub.status.busy":"2022-07-03T07:37:53.968766Z","iopub.status.idle":"2022-07-03T07:37:54.231348Z","shell.execute_reply":"2022-07-03T07:37:54.229925Z","shell.execute_reply.started":"2022-07-03T07:37:53.969169Z"},"id":"YSJKRm5SvS9y","trusted":true},"outputs":[],"source":["\n","def cleanResume(resumeText):\n","    resumeText = re.sub('http\\S+\\s*', ' ', resumeText)  # remove URLs\n","    resumeText = re.sub('RT|cc', ' ', resumeText)  # remove RT and cc\n","    resumeText = re.sub('#\\S+', '', resumeText)  # remove hashtags\n","    resumeText = re.sub('@\\S+', '  ', resumeText)  # remove mentions\n","    resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\n","    resumeText = re.sub(r'[^\\x00-\\x7f]',r' ', resumeText) \n","    resumeText = re.sub('\\s+', ' ', resumeText)  # remove extra whitespace\n","    return resumeText\n","    \n","df['cleaned_resume'] = df.Resume.apply(lambda x: cleanResume(x))"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2022-07-03T07:37:59.279042Z","iopub.status.busy":"2022-07-03T07:37:59.278587Z","iopub.status.idle":"2022-07-03T07:37:59.291362Z","shell.execute_reply":"2022-07-03T07:37:59.290221Z","shell.execute_reply.started":"2022-07-03T07:37:59.279007Z"},"id":"qZdl03XqvhXA","outputId":"8e891968-5a21-4c35-fdb0-2d4b83ef2177","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Category</th>\n","      <th>Resume</th>\n","      <th>cleaned_resume</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Data Science</td>\n","      <td>Skills * Programming Languages: Python (pandas...</td>\n","      <td>Skills Programming Languages Python pandas num...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Data Science</td>\n","      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n","      <td>Education Details May 2013 to May 2017 B E UIT...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Data Science</td>\n","      <td>Areas of Interest Deep Learning, Control Syste...</td>\n","      <td>Areas of Interest Deep Learning Control System...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Data Science</td>\n","      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n","      <td>Skills R Python SAP HANA Tableau SAP HANA SQL ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Data Science</td>\n","      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n","      <td>Education Details MCA YMCAUST Faridabad Haryan...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Category                                             Resume  \\\n","0  Data Science  Skills * Programming Languages: Python (pandas...   \n","1  Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...   \n","2  Data Science  Areas of Interest Deep Learning, Control Syste...   \n","3  Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...   \n","4  Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab...   \n","\n","                                      cleaned_resume  \n","0  Skills Programming Languages Python pandas num...  \n","1  Education Details May 2013 to May 2017 B E UIT...  \n","2  Areas of Interest Deep Learning Control System...  \n","3  Skills R Python SAP HANA Tableau SAP HANA SQL ...  \n","4  Education Details MCA YMCAUST Faridabad Haryan...  "]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"markdown","metadata":{"id":"TliJyalEaWaE"},"source":["## **Checking the most common words from resume**"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2022-07-03T07:38:08.652180Z","iopub.status.busy":"2022-07-03T07:38:08.651744Z","iopub.status.idle":"2022-07-03T07:38:10.920103Z","shell.execute_reply":"2022-07-03T07:38:10.918586Z","shell.execute_reply.started":"2022-07-03T07:38:08.652145Z"},"id":"LcXkD5KOQscZ","outputId":"3fd185cf-7d23-47d7-c209-0bc025f374c9","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[('Exprience', 616), ('company', 520), ('months', 515), ('Details', 510), ('description', 458), ('1', 348), ('Project', 299), ('data', 242), ('project', 231), ('6', 227), ('Maharashtra', 217), ('year', 215), ('SQL', 215), ('team', 207), ('Less', 199), ('using', 197), ('January', 189), ('Skill', 175), ('Management', 167), ('Ltd', 159), ('Pune', 158), ('C', 151), ('Education', 144), ('management', 143), ('Data', 140), ('Developer', 137), ('Engineering', 134), ('database', 133), ('Java', 130), ('Database', 127), ('monthsCompany', 125), ('System', 123), ('University', 123), ('Server', 123), ('Pvt', 122), ('India', 120), ('like', 118), ('The', 117), ('Responsibilities', 117), ('various', 116), ('A', 113), ('business', 113), ('2', 113), ('development', 112), ('reports', 111), ('application', 110), ('issues', 106), ('system', 106), ('Mumbai', 106), ('Test', 105)]\n"]}],"source":["oneSetOfStopWords = set(stopwords.words('english')+['``',\"''\"])\n","totalWords =[]\n","Sentences = df['Resume'].values\n","cleanedSentences = \"\"\n","for records in Sentences:\n","    cleanedText = cleanResume(records)\n","    cleanedSentences += cleanedText\n","    requiredWords = nltk.word_tokenize(cleanedText)\n","    for word in requiredWords:\n","        if word not in oneSetOfStopWords and word not in string.punctuation:\n","            totalWords.append(word)\n","    \n","wordfreqdist = nltk.FreqDist(totalWords)\n","mostcommon = wordfreqdist.most_common(50)\n","print(mostcommon)"]},{"cell_type":"markdown","metadata":{},"source":["***Now, we will encode the ‘Category’ column using LabelEncoding. Even though the ‘Category’ column is ‘Nominal’ data we are using LabelEncong because the ‘Category’ column is our ‘target’ column. By performing LabelEncoding each category will become a class and we will be building a multiclass classification model.***"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2022-07-03T07:38:17.177277Z","iopub.status.busy":"2022-07-03T07:38:17.176908Z","iopub.status.idle":"2022-07-03T07:38:17.183616Z","shell.execute_reply":"2022-07-03T07:38:17.182783Z","shell.execute_reply.started":"2022-07-03T07:38:17.177247Z"},"id":"ZSN0GYr1wfH7","trusted":true},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","var_mod = ['Category']\n","le = LabelEncoder()\n","for i in var_mod:\n","    df[i] = le.fit_transform(df[i])"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2022-07-03T07:38:21.966120Z","iopub.status.busy":"2022-07-03T07:38:21.963950Z","iopub.status.idle":"2022-07-03T07:38:21.974414Z","shell.execute_reply":"2022-07-03T07:38:21.973541Z","shell.execute_reply.started":"2022-07-03T07:38:21.966065Z"},"id":"RaWohVLUwfLJ","outputId":"d5b8601a-b148-4260-e788-54c10917cd29","trusted":true},"outputs":[{"data":{"text/plain":["Category\n","15    13\n","7     11\n","6     10\n","0     10\n","12    10\n","9      7\n","13     7\n","8      7\n","2      7\n","23     7\n","5      6\n","4      6\n","21     6\n","14     6\n","20     6\n","1      6\n","11     5\n","22     5\n","17     5\n","16     5\n","10     5\n","3      5\n","18     4\n","24     4\n","19     3\n","Name: count, dtype: int64"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["df.Category.value_counts()"]},{"cell_type":"markdown","metadata":{"id":"5ySEruXJauvE"},"source":["## **Building Model**\n","\n","### **Spliting data into train and test**"]},{"cell_type":"markdown","metadata":{},"source":["***Here we will preprocess and convert the ‘cleaned_resume’ column into vectors. There are many ways to do that like ‘Bag of Words’, ‘Tf-Idf’, ‘Word2Vec’ and a combination of these methods.***\n","\n","**We will be using the ‘Tf-Idf’ method to get the vectors in this approach.**"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2022-07-03T07:38:31.512787Z","iopub.status.busy":"2022-07-03T07:38:31.512399Z","iopub.status.idle":"2022-07-03T07:38:32.073495Z","shell.execute_reply":"2022-07-03T07:38:32.072382Z","shell.execute_reply.started":"2022-07-03T07:38:31.512751Z"},"id":"P5cU6uGUyVNb","outputId":"b42f74d4-6c37-45b3-9763-b159fcabe4b3","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Feature completed .....\n"]}],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","#from scipy.sparse import hstack\n","\n","requiredText = df['cleaned_resume'].values\n","requiredTarget = df['Category'].values\n","\n","word_vectorizer = TfidfVectorizer(\n","    sublinear_tf=True,\n","    stop_words='english')\n","word_vectorizer.fit(requiredText)\n","WordFeatures = word_vectorizer.transform(requiredText)\n","\n","print (\"Feature completed .....\")"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2022-07-03T07:38:36.869762Z","iopub.status.busy":"2022-07-03T07:38:36.869369Z","iopub.status.idle":"2022-07-03T07:38:36.882489Z","shell.execute_reply":"2022-07-03T07:38:36.881344Z","shell.execute_reply.started":"2022-07-03T07:38:36.869732Z"},"id":"VF8GDP6ry6sw","outputId":"27df9ac1-e050-45a9-ee04-97830002cbbe","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(132, 7351)\n","(34, 7351)\n"]}],"source":["X_train,X_test,y_train,y_test = train_test_split(WordFeatures,requiredTarget,random_state=1, test_size=0.2,shuffle=True, stratify=requiredTarget)\n","print(X_train.shape)\n","print(X_test.shape)"]},{"cell_type":"markdown","metadata":{},"source":["**We will be using the ‘One vs Rest’ method with ‘KNeighborsClassifier’ to build this multiclass classification model.**"]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2022-07-03T07:38:41.947285Z","iopub.status.busy":"2022-07-03T07:38:41.946840Z","iopub.status.idle":"2022-07-03T07:38:42.016746Z","shell.execute_reply":"2022-07-03T07:38:42.015819Z","shell.execute_reply.started":"2022-07-03T07:38:41.947249Z"},"id":"orErFafxy_gk","trusted":true},"outputs":[],"source":["from sklearn.multiclass import OneVsRestClassifier\n","from sklearn import metrics\n","from sklearn.metrics import accuracy_score\n","from sklearn.neighbors import KNeighborsClassifier"]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2022-07-03T07:38:48.129528Z","iopub.status.busy":"2022-07-03T07:38:48.128900Z","iopub.status.idle":"2022-07-03T07:38:51.148646Z","shell.execute_reply":"2022-07-03T07:38:51.147347Z","shell.execute_reply.started":"2022-07-03T07:38:48.129478Z"},"id":"neJPQtPXzQkK","outputId":"c1a473db-76a8-484a-8cab-f150595c3748","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of KNeighbors Classifier on training: 0.91\n","Accuracy of KNeighbors Classifier on test:     0.82\n"]}],"source":["clf = OneVsRestClassifier(KNeighborsClassifier())\n","clf.fit(X_train, y_train)\n","prediction = clf.predict(X_test)\n","print('Accuracy of KNeighbors Classifier on training: {:.2f}'.format(clf.score(X_train, y_train)))\n","print('Accuracy of KNeighbors Classifier on test:     {:.2f}'.format(clf.score(X_test, y_test)))"]},{"cell_type":"markdown","metadata":{},"source":["**We can see that results are awesome. We are able to classify each Category of a given resume with 99% accuracy.**\n","\n","***We can also check the detailed classification report for each class or category.***"]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.execute_input":"2022-07-03T07:38:57.488539Z","iopub.status.busy":"2022-07-03T07:38:57.488103Z","iopub.status.idle":"2022-07-03T07:38:57.505344Z","shell.execute_reply":"2022-07-03T07:38:57.503998Z","shell.execute_reply.started":"2022-07-03T07:38:57.488506Z"},"id":"z3S1bWigz1sI","outputId":"14d10dcc-3f04-4d7e-caf7-396c00303fbc","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"," Classification report for classifier OneVsRestClassifier(estimator=KNeighborsClassifier()):\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       0.00      0.00      0.00         1\n","           2       0.50      1.00      0.67         1\n","           3       1.00      1.00      1.00         1\n","           4       1.00      1.00      1.00         1\n","           5       1.00      1.00      1.00         1\n","           6       1.00      0.50      0.67         2\n","           7       1.00      1.00      1.00         2\n","           8       1.00      0.50      0.67         2\n","           9       0.67      1.00      0.80         2\n","          10       0.00      0.00      0.00         1\n","          11       1.00      1.00      1.00         1\n","          12       1.00      1.00      1.00         2\n","          13       0.50      1.00      0.67         1\n","          14       1.00      1.00      1.00         1\n","          15       0.75      1.00      0.86         3\n","          16       1.00      1.00      1.00         1\n","          17       1.00      1.00      1.00         1\n","          18       1.00      1.00      1.00         1\n","          19       0.50      1.00      0.67         1\n","          20       1.00      1.00      1.00         1\n","          21       0.50      1.00      0.67         1\n","          22       1.00      1.00      1.00         1\n","          23       1.00      0.50      0.67         2\n","          24       0.00      0.00      0.00         1\n","\n","    accuracy                           0.82        34\n","   macro avg       0.78      0.82      0.77        34\n","weighted avg       0.81      0.82      0.79        34\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]}],"source":["print(\"\\n Classification report for classifier %s:\\n%s\\n\" % (clf, metrics.classification_report(y_test, prediction)))"]},{"cell_type":"markdown","metadata":{},"source":["**Where, 0, 1, 2…. are the job categories. We get the actual labels from the label encoder that we used.**"]},{"cell_type":"code","execution_count":81,"metadata":{"execution":{"iopub.execute_input":"2022-07-03T07:39:02.954513Z","iopub.status.busy":"2022-07-03T07:39:02.954040Z","iopub.status.idle":"2022-07-03T07:39:02.963354Z","shell.execute_reply":"2022-07-03T07:39:02.962074Z","shell.execute_reply.started":"2022-07-03T07:39:02.954477Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array(['Advocate', 'Arts', 'Automation Testing', 'Blockchain',\n","       'Business Analyst', 'Civil Engineer', 'Data Science', 'Database',\n","       'DevOps Engineer', 'DotNet Developer', 'ETL Developer',\n","       'Electrical Engineering', 'HR', 'Hadoop', 'Health and fitness',\n","       'Java Developer', 'Mechanical Engineer',\n","       'Network Security Engineer', 'Operations Manager', 'PMO',\n","       'Python Developer', 'SAP Developer', 'Sales', 'Testing',\n","       'Web Designing'], dtype=object)"]},"execution_count":81,"metadata":{},"output_type":"execute_result"}],"source":["le.classes_"]},{"cell_type":"markdown","metadata":{},"source":["**Here ‘Advocate’ is class 0, ‘Arts’ is class 1, and so on…**"]},{"cell_type":"markdown","metadata":{},"source":["## SCreening"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: python-docx in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.0)\n","Requirement already satisfied: lxml>=3.1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-docx) (5.2.1)\n","Requirement already satisfied: typing-extensions in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-docx) (4.8.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install python-docx\n"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[],"source":["# import docx\n","# from sklearn.metrics.pairwise import cosine_similarity\n","\n","# def read_docx(file_path):\n","#     \"\"\"\n","#     Reads a .docx file and returns the text.\n","#     \"\"\"\n","#     doc = docx.Document(file_path)\n","#     fullText = []\n","#     for para in doc.paragraphs:\n","#         fullText.append(para.text)\n","#     return '\\n'.join(fullText)\n","\n","# def resume_screening(model, vectorizer, le, resume_path):\n","#     \"\"\"\n","#     Screens a resume against the job categories.\n","#     \"\"\"\n","#     # Read resume content\n","#     resume_text = read_docx(resume_path)\n","    \n","#     # Clean the resume text\n","#     cleaned_resume = cleanResume(resume_text)\n","    \n","#     # Convert to TF-IDF features\n","#     resume_vec = vectorizer.transform([cleaned_resume])\n","    \n","#     # Predict the job category\n","#     pred = model.predict(resume_vec)\n","#     pred_proba = model.predict_proba(resume_vec)\n","    \n","#     # Find the best match category name\n","#     best_match_category = le.inverse_transform([pred[0]])[0]\n","#     best_match_score = max(pred_proba[0]) * 100  # Convert to percentage\n","    \n","#     print(f\"Best Match Job Category: {best_match_category}\")\n","#     print(f\"Match Score: {best_match_score:.2f}%\")\n","    \n","#     return best_match_category, best_match_score\n","\n","# # Example usage:\n","# resume_path = \"John Doe.docx\"\n","# best_match_category, best_match_score = resume_screening(clf, word_vectorizer, le, resume_path)\n"]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[],"source":["# import docx\n","\n","# def read_docx(file_path):\n","#     \"\"\"\n","#     Reads a .docx file and returns the text.\n","#     \"\"\"\n","#     doc = docx.Document(file_path)\n","#     fullText = []\n","#     for para in doc.paragraphs:\n","#         fullText.append(para.text)\n","#     return '\\n'.join(fullText)\n","\n","# def resume_screening(model, vectorizer, le, resume_path):\n","#     \"\"\"\n","#     Screens a resume against a specified job category.\n","#     \"\"\"\n","#     # Read resume content\n","#     resume_text = read_docx(resume_path)\n","    \n","#     # Clean the resume text\n","#     cleaned_resume = cleanResume(resume_text)\n","    \n","#     # Convert to TF-IDF features\n","#     resume_vec = vectorizer.transform([cleaned_resume])\n","    \n","#     # Prompt user to specify the job category\n","#     print(\"Available job categories:\")\n","#     for category in le.classes_:\n","#         print(\"-\", category)\n","#     target_category = input(\"Enter the job category you are interested in: \")\n","    \n","#     if target_category not in le.classes_:\n","#         print(\"Invalid job category.\")\n","#         return\n","    \n","#     # Predict the job category\n","#     pred = model.predict(resume_vec)\n","#     pred_proba = model.predict_proba(resume_vec)\n","    \n","#     # Find the match score for the specified job category\n","#     target_category_index = le.transform([target_category])[0]\n","#     match_score = pred_proba[0][target_category_index] * 100  # Convert to percentage\n","    \n","#     print(f\"Match Score for {target_category}: {match_score:.2f}%\")\n","    \n","#     return target_category, match_score\n","\n","# # Example usage:\n","# resume_path = \"John Doe.docx\"\n","# target_category, match_score = resume_screening(clf, word_vectorizer, le, resume_path)\n"]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[],"source":["# def resume_screening_with_threshold(model, vectorizer, le, resume_path, threshold=0.1):\n","#     \"\"\"\n","#     Screens a resume and suggests job categories based on a confidence threshold.\n","#     \"\"\"\n","#     # Read and clean the resume\n","#     resume_text = read_docx(resume_path)\n","#     cleaned_resume = cleanResume(resume_text)\n","    \n","#     # Convert to TF-IDF features\n","#     resume_vec = vectorizer.transform([cleaned_resume])\n","    \n","#     # Get predictions with probabilities\n","#     pred_proba = model.predict_proba(resume_vec)[0]\n","    \n","#     # Mapping probabilities to job categories\n","#     proba_category_mapping = [(le.inverse_transform([i])[0], proba) for i, proba in enumerate(pred_proba)]\n","    \n","#     # Filter based on threshold\n","#     suggested_categories = [ (category, proba*100) for category, proba in proba_category_mapping if proba >= threshold]\n","    \n","#     if not suggested_categories:\n","#         print(\"No matches found above the threshold.\")\n","#     else:\n","#         print(\"Suggested categories based on resume content:\")\n","#         for category, match_score in suggested_categories:\n","#             print(f\"{category}: {match_score:.2f}%\")\n","\n","# # Example usage\n","# resume_path = \"John Doe.docx\"\n","# resume_screening_with_threshold(clf, word_vectorizer, le, resume_path, threshold=0.1)\n"]},{"cell_type":"code","execution_count":86,"metadata":{},"outputs":[],"source":["# def resume_screening_with_suggestions(model, vectorizer, le, resume_path, threshold=0.1):\n","#     \"\"\"\n","#     Screens a resume and suggests job categories based on a confidence threshold.\n","#     \"\"\"\n","#     # Read and clean the resume\n","#     resume_text = read_docx(resume_path)\n","#     cleaned_resume = cleanResume(resume_text)\n","    \n","#     # Convert to TF-IDF features\n","#     resume_vec = vectorizer.transform([cleaned_resume])\n","    \n","#     # Get predictions with probabilities\n","#     pred_proba = model.predict_proba(resume_vec)[0]\n","    \n","#     # Mapping probabilities to job categories\n","#     proba_category_mapping = [(le.inverse_transform([i])[0], proba) for i, proba in enumerate(pred_proba)]\n","    \n","#     # Sort categories by probability\n","#     proba_category_mapping.sort(key=lambda x: x[1], reverse=True)\n","    \n","#     # Filter based on threshold\n","#     suggested_categories = [ (category, proba*100) for category, proba in proba_category_mapping if proba >= threshold]\n","    \n","#     if not suggested_categories:\n","#         print(\"No matches found above the threshold.\")\n","#     else:\n","#         print(\"Suggested job categories based on resume content:\")\n","#         for category, match_score in suggested_categories:\n","#             print(f\"- {category}: {match_score:.2f}%\")\n","\n","# # Example usage\n","# resume_path = \"John Doe.docx\"\n","# resume_screening_with_suggestions(clf, word_vectorizer, le, resume_path, threshold=0.1)\n"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[],"source":["# import re\n","# from datetime import datetime\n","\n","# def extract_overall_experience_years(resume_text):\n","#     \"\"\"\n","#     Calculates overall experience years from the resume text, accounting for overlapping jobs.\n","#     \"\"\"\n","#     date_pattern = r'((?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)?\\s*\\d{4})\\s*-\\s*((?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)?\\s*(?:\\d{4}|Present))'\n","#     matches = re.findall(date_pattern, resume_text, re.IGNORECASE)\n","\n","#     min_start_year = datetime.now().year\n","#     max_end_year = 0\n","\n","#     for start, end in matches:\n","#         start_year = int(re.search(r'\\d{4}', start).group())\n","#         end_year = datetime.now().year if \"Present\" in end else int(re.search(r'\\d{4}', end).group())\n","\n","#         # Update the earliest start year and latest end year found\n","#         if start_year < min_start_year:\n","#             min_start_year = start_year\n","#         if end_year > max_end_year:\n","#             max_end_year = end_year\n","\n","#     total_experience = max_end_year - min_start_year\n","#     return total_experience\n","    \n","   \n","\n","\n","# def resume_screening_with_suggestions(model, vectorizer, le, resume_path, threshold=0.1):\n","#     \"\"\"\n","#     Screens a resume, calculates total experience, and suggests job categories based on a confidence threshold.\n","#     \"\"\"\n","#     # Read and clean the resume\n","#     resume_text = read_docx(resume_path)\n","#     cleaned_resume = cleanResume(resume_text)\n","    \n","#     # Calculate experience years\n","#     experience_years = extract_experience_years(resume_text)\n","#     print(f\"Total experience: {experience_years} years\")\n","    \n","#     # Convert to TF-IDF features\n","#     resume_vec = vectorizer.transform([cleaned_resume])\n","    \n","#     # Get predictions with probabilities\n","#     pred_proba = model.predict_proba(resume_vec)[0]\n","    \n","#     # Mapping probabilities to job categories\n","#     proba_category_mapping = [(le.inverse_transform([i])[0], proba) for i, proba in enumerate(pred_proba)]\n","    \n","#     # Sort categories by probability\n","#     proba_category_mapping.sort(key=lambda x: x[1], reverse=True)\n","    \n","#     # Filter based on threshold\n","#     suggested_categories = [ (category, proba*100) for category, proba in proba_category_mapping if proba >= threshold]\n","    \n","#     if not suggested_categories:\n","#         print(\"No matches found above the threshold.\")\n","#     else:\n","#         print(\"Suggested job categories based on resume content:\")\n","#         for category, match_score in suggested_categories:\n","#             print(f\"- {category}: {match_score:.2f}%\")\n","\n","# # Example usage\n","# resume_path = \"John Doe.docx\"\n","# resume_screening_with_suggestions(clf, word_vectorizer, le, resume_path, threshold=0.1)\n"]},{"cell_type":"code","execution_count":88,"metadata":{},"outputs":[],"source":["# import pandas as pd\n","# import glob\n","\n","# def process_resumes(resume_paths, model, vectorizer, le, threshold=0.1):\n","#     \"\"\"\n","#     Processes multiple resumes and generates classification results for each one.\n","#     Returns a DataFrame summarizing the job categories with the highest match scores for each candidate.\n","#     \"\"\"\n","#     results = []\n","\n","#     for resume_path in resume_paths:\n","#         # Read and clean the resume\n","#         resume_text = read_docx(resume_path)\n","#         cleaned_resume = cleanResume(resume_text)\n","        \n","#         # Convert to TF-IDF features\n","#         resume_vec = vectorizer.transform([cleaned_resume])\n","        \n","#         # Get predictions with probabilities\n","#         pred_proba = model.predict_proba(resume_vec)[0]\n","        \n","#         # Mapping probabilities to job categories\n","#         proba_category_mapping = [(le.inverse_transform([i])[0], proba) for i, proba in enumerate(pred_proba)]\n","        \n","#         # Sort categories by probability\n","#         proba_category_mapping.sort(key=lambda x: x[1], reverse=True)\n","        \n","#         # Filter based on threshold\n","#         suggested_categories = [(category, proba*100) for category, proba in proba_category_mapping if proba >= threshold]\n","        \n","#         # Store results\n","#         results.append({\n","#             'Resume': resume_path,\n","#             'Job Categories': suggested_categories\n","#         })\n","    \n","#     # Create DataFrame from results\n","#     df_results = pd.DataFrame(results)\n","    \n","#     # Generate a table summarizing the job categories with the highest match scores for each candidate\n","#     summary_table = pd.DataFrame(columns=['Job Category', 'Candidate', 'Match Score'])\n","\n","#     for _, row in df_results.iterrows():\n","#         resume = row['Resume']\n","#         categories = row['Job Categories']\n","        \n","#         for category, score in categories:\n","#             candidate = resume.split('.')[0]  # Extract candidate name from file name\n","#             summary_table = pd.concat([summary_table, pd.DataFrame({'Job Category': [category], 'Candidate': [candidate], 'Match Score': [score]})], ignore_index=True)\n","    \n","#     return summary_table\n","\n","# # Automatically find all .docx files in the code file's directory\n","# resume_paths = glob.glob('./*.docx')\n","\n","# # Process the found resume files\n","# result_table = process_resumes(resume_paths, clf, word_vectorizer, le, threshold=0.1)\n","# print(result_table)\n"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[],"source":["# import pandas as pd\n","# import glob\n","\n","# def process_resumes(resume_paths, model, vectorizer, le, threshold=0.1):\n","#     \"\"\"\n","#     Processes multiple resumes and generates classification results for each one.\n","#     Returns a DataFrame summarizing the job categories with the highest match scores for each candidate.\n","#     \"\"\"\n","#     results = []\n","\n","#     for resume_path in resume_paths:\n","#         # Read and clean the resume\n","#         resume_text = read_docx(resume_path)\n","#         cleaned_resume = cleanResume(resume_text)\n","        \n","#         # Convert to TF-IDF features\n","#         resume_vec = vectorizer.transform([cleaned_resume])\n","        \n","#         # Get predictions with probabilities\n","#         pred_proba = model.predict_proba(resume_vec)[0]\n","        \n","#         # Mapping probabilities to job categories\n","#         proba_category_mapping = [(le.inverse_transform([i])[0], proba) for i, proba in enumerate(pred_proba)]\n","        \n","#         # Sort categories by probability\n","#         proba_category_mapping.sort(key=lambda x: x[1], reverse=True)\n","        \n","#         # Filter based on threshold\n","#         suggested_categories = [(category, proba*100) for category, proba in proba_category_mapping if proba >= threshold]\n","        \n","#         # Extract experience years\n","#         experience_years = extract_overall_experience_years(resume_text)\n","        \n","#         # Store results\n","#         results.append({\n","#             'Resume': resume_path,\n","#             'Job Categories': suggested_categories,\n","#             'Experience Years': experience_years\n","#         })\n","    \n","#     # Create DataFrame from results\n","#     df_results = pd.DataFrame(results)\n","    \n","#     # Generate a table summarizing the job categories with the highest match scores for each candidate\n","#     summary_table = pd.DataFrame(columns=['Job Category', 'Candidate', 'Match Score', 'Experience Years'])\n","\n","#     for _, row in df_results.iterrows():\n","#         resume = row['Resume']\n","#         categories = row['Job Categories']\n","#         experience_years = row['Experience Years']\n","        \n","#         for category, score in categories:\n","#             candidate = resume.split('.')[0]  # Extract candidate name from file name\n","#             summary_table = pd.concat([summary_table, pd.DataFrame({'Job Category': [category], 'Candidate': [candidate], 'Match Score': [score], 'Experience Years': [experience_years]})], ignore_index=True)\n","    \n","#     return summary_table\n","\n","# # Automatically find all .docx files in the code file's directory\n","# resume_paths = glob.glob('./*.docx')\n","\n","# # Process the found resume files\n","# result_table = process_resumes(resume_paths, clf, word_vectorizer, le, threshold=0.1)\n","# print(result_table)\n"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[],"source":["# import pandas as pd\n","# import glob\n","# import os\n","# import docx\n","\n","# def read_docx(file_path):\n","#     doc = docx.Document(file_path)\n","#     fullText = []\n","#     for para in doc.paragraphs:\n","#         fullText.append(para.text)\n","#     return '\\n'.join(fullText)\n","\n","# def process_resumes(resume_paths, model, vectorizer, le, threshold=0.1):\n","#     \"\"\"\n","#     Processes multiple resumes and generates classification results for each one.\n","#     Returns a DataFrame summarizing the job categories with the highest match scores for each candidate.\n","#     \"\"\"\n","#     results = []\n","\n","#     for resume_path in resume_paths:\n","#         # Read the resume text\n","#         resume_text = read_docx(resume_path)\n","        \n","#         # Extract candidate's name from the file name\n","#         candidate_name = os.path.splitext(os.path.basename(resume_path))[0]\n","        \n","#         # Clean the resume\n","#         cleaned_resume = cleanResume(resume_text)\n","        \n","#         # Convert to TF-IDF features\n","#         resume_vec = vectorizer.transform([cleaned_resume])\n","        \n","#         # Get predictions with probabilities\n","#         pred_proba = model.predict_proba(resume_vec)[0]\n","        \n","#         # Mapping probabilities to job categories\n","#         proba_category_mapping = [(le.inverse_transform([i])[0], proba) for i, proba in enumerate(pred_proba)]\n","        \n","#         # Sort categories by probability\n","#         proba_category_mapping.sort(key=lambda x: x[1], reverse=True)\n","        \n","#         # Filter based on threshold\n","#         suggested_categories = [(category, proba*100) for category, proba in proba_category_mapping if proba >= threshold]\n","        \n","#         # Store results\n","#         results.append({\n","#             'Candidate Name': candidate_name,\n","#             'Job Categories': suggested_categories\n","#         })\n","    \n","#     # Create DataFrame from results\n","#     df_results = pd.DataFrame(results)\n","    \n","#     # Generate a table summarizing the job categories with the highest match scores for each candidate\n","#     summary_table = pd.DataFrame(columns=['Candidate Name', 'Job Category', 'Match Score'])\n","\n","#     for _, row in df_results.iterrows():\n","#         candidate_name = row['Candidate Name']\n","#         categories = row['Job Categories']\n","        \n","#         for category, score in categories:\n","#             summary_table = pd.concat([summary_table, pd.DataFrame({'Candidate Name': [candidate_name], 'Job Category': [category], 'Match Score': [score]})], ignore_index=True)\n","    \n","#     return summary_table\n","\n","# # Automatically find all .docx files in the code file's directory\n","# resume_paths = glob.glob('./*.docx')\n","\n","# # Process the found resume files\n","# result_table = process_resumes(resume_paths, clf, word_vectorizer, le, threshold=0.1)\n","# print(result_table)\n"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[],"source":["# def print_results_by_category(df):\n","#     # Extract unique job categories\n","#     job_categories = df['Job Category'].unique()\n","    \n","#     for category in job_categories:\n","#         # Filter DataFrame for the current category\n","#         category_df = df[df['Job Category'] == category]\n","        \n","#         print(f\"{category} | Candidate Name | Match Score\")\n","#         print(\"-\" * (len(category) + 34))  # Adjust based on your column width\n","        \n","#         # Iterate through rows in the filtered DataFrame\n","#         for index, row in category_df.iterrows():\n","#             print(f\"  {row['Candidate Name']: <20} | {row['Match Score']: >10}%\")\n","        \n","#         print(\"\\n\")  # Print a newline for better separation between categories\n","\n","# # Assuming 'result_table' is your DataFrame\n","# print_results_by_category(result_table)\n"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[],"source":["# def print_results_by_category(df, le):\n","#     # Prompt user to specify the job category\n","#     print(\"Available job categories:\")\n","#     for category in le.classes_:\n","#         print(\"-\", category)\n","#     target_category = input(\"Enter the job category you are interested in: \")\n","    \n","#     if target_category not in le.classes_:\n","#         print(\"Invalid job category.\")\n","#         return\n","\n","#     # Filter DataFrame for the chosen category\n","#     category_df = df[df['Job Category'] == target_category]\n","    \n","#     print(f\"\\n{target_category} | Candidate Name | Match Score\")\n","#     print(\"-\" * (len(target_category) + 50))  # Adjust based on your column width\n","    \n","#     # Iterate through rows in the filtered DataFrame\n","#     for index, row in category_df.iterrows():\n","#         print(f\"  {row['Candidate Name']: <20} | {row['Match Score']: >10}%\")\n","    \n","#     print(\"\\n\")  # Print a newline for better separation\n","\n","# # Assuming 'result_table' is your DataFrame\n","# print_results_by_category(result_table, le)\n"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[],"source":["# from tabulate import tabulate\n","\n","# def print_results_by_category(df, le):\n","#     # Prompt user to specify the job category\n","#     print(\"Available job categories:\")\n","#     for category in le.classes_:\n","#         print(\"-\", category)\n","#     target_category = input(\"Enter the job category you are interested in: \")\n","    \n","#     if target_category not in le.classes_:\n","#         print(\"Invalid job category.\")\n","#         return\n","\n","#     # Filter DataFrame for the chosen category\n","#     category_df = df[df['Job Category'] == target_category]\n","    \n","#     # Prepare data for tabulate\n","#     headers = ['Candidate Name', 'Match Score']\n","#     data = category_df[['Candidate Name', 'Match Score']].values.tolist()\n","    \n","#     # Calculate the width of the table\n","#     table_width = sum(len(str(header)) for header in headers) + len(headers) * 3\n","    \n","#     # Print table header with category name centered\n","#     print(\"\\n\" + target_category.center(table_width) + \"\\n\")\n","    \n","#     # Print table using tabulate\n","#     print(tabulate(data, headers=headers, tablefmt=\"pretty\"))\n","\n","# # Assuming 'result_table' is your DataFrame\n","# print_results_by_category(result_table, le)\n"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[],"source":["# from tabulate import tabulate\n","\n","# def print_results_by_category(df, le):\n","#     # Print the list of available job categories only once at the beginning\n","#     print(\"\\nAvailable job categories:\")\n","#     for category in le.classes_:\n","#         print(\"-\", category)\n","#     print(\"Enter 'exit' to stop.\")\n","    \n","#     while True:\n","#         # Prompt user to specify the job category\n","#         target_category = input(\"\\nEnter the job category you are interested in or 'exit' to stop: \")\n","        \n","#         # Check for exit condition\n","#         if target_category.lower() == 'exit':\n","#             break\n","        \n","#         if target_category not in le.classes_:\n","#             print(\"Invalid job category. Please try again.\")\n","#             continue\n","\n","#         # Filter DataFrame for the chosen category\n","#         category_df = df[df['Job Category'] == target_category]\n","        \n","#         # Prepare data for tabulate\n","#         headers = ['Candidate Name', 'Match Score']\n","#         data = category_df[['Candidate Name', 'Match Score']].values.tolist()\n","        \n","#         # Calculate the width of the table\n","#         table_width = sum(len(str(header)) for header in headers) + len(headers) * 3 + 5  # Adjust for spacing\n","        \n","#         # Print table header with category name centered\n","#         print(\"\\n\" + target_category.center(table_width) + \"\\n\")\n","        \n","#         # Print table using tabulate\n","#         if not data:\n","#             print(f\"No candidates found for {target_category}.\")\n","#         else:\n","#             print(tabulate(data, headers=headers, tablefmt=\"pretty\"))\n","\n","# # Assuming 'result_table' is your DataFrame and 'le' is your LabelEncoder\n","# print_results_by_category(result_table, le)\n"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["  Candidate Name         Job Category  Match Score Experience\n","0  Alice Johnson             Advocate        100.0          8\n","1          Ayush   Health and fitness         40.0       Null\n","2          Ayush           Blockchain         20.0       Null\n","3          Ayush  Mechanical Engineer         20.0       Null\n","4          Ayush                Sales         20.0       Null\n","5       Jane Doe         Data Science        100.0         10\n","6     John smith         Data Science         60.0         12\n","7     John smith     Python Developer         40.0         12\n","8      Tim David         Data Science         80.0          4\n","9      Tim David     Python Developer         20.0          4\n","Results saved to data\\resume_classification_results.csv.\n"]}],"source":["import pandas as pd\n","import glob\n","import os\n","import docx\n","import re\n","from datetime import datetime\n","\n","def read_docx(file_path):\n","    doc = docx.Document(file_path)\n","    fullText = []\n","    for para in doc.paragraphs:\n","        fullText.append(para.text)\n","    return '\\n'.join(fullText)\n","\n","def extract_overall_experience_years(resume_text):\n","    \"\"\"\n","    Calculates overall experience years from the resume text, accounting for overlapping jobs.\n","    \"\"\"\n","    date_pattern = r'((?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)?\\s*\\d{4})\\s*-\\s*((?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)?\\s*(?:\\d{4}|Present))'\n","    matches = re.findall(date_pattern, resume_text, re.IGNORECASE)\n","\n","    if not matches:\n","        return \"Null\"  # Return \"Null\" if no dates found\n","\n","    min_start_year = datetime.now().year\n","    max_end_year = 0\n","\n","    for start, end in matches:\n","        start_year = int(re.search(r'\\d{4}', start).group())\n","        end_year = datetime.now().year if \"Present\" in end else int(re.search(r'\\d{4}', end).group())\n","\n","        if start_year < min_start_year:\n","            min_start_year = start_year\n","        if end_year > max_end_year:\n","            max_end_year = end_year\n","\n","    total_experience = max_end_year - min_start_year\n","    return total_experience\n","\n","def process_resumes(resume_paths, model, vectorizer, le, threshold=0.1):\n","    results = []\n","\n","    for resume_path in resume_paths:\n","        resume_text = read_docx(resume_path)\n","        candidate_name = os.path.splitext(os.path.basename(resume_path))[0]\n","        cleaned_resume = cleanResume(resume_text)  # Assuming you have a cleanResume function\n","        \n","        resume_vec = vectorizer.transform([cleaned_resume])\n","        pred_proba = model.predict_proba(resume_vec)[0]\n","        \n","        proba_category_mapping = [(le.inverse_transform([i])[0], proba) for i, proba in enumerate(pred_proba)]\n","        proba_category_mapping.sort(key=lambda x: x[1], reverse=True)\n","        \n","        suggested_categories = [(category, proba*100) for category, proba in proba_category_mapping if proba >= threshold]\n","        \n","        # Extract overall experience\n","        overall_experience = extract_overall_experience_years(resume_text)\n","        \n","        results.append({\n","            'Candidate Name': candidate_name,\n","            'Job Categories': suggested_categories,\n","            'Experience': overall_experience  # Add experience to the results\n","        })\n","    \n","    df_results = pd.DataFrame(results)\n","    summary_table = pd.DataFrame(columns=['Candidate Name', 'Job Category', 'Match Score', 'Experience'])\n","\n","    for _, row in df_results.iterrows():\n","        candidate_name = row['Candidate Name']\n","        categories = row['Job Categories']\n","        experience = row['Experience']\n","        \n","        for category, score in categories:\n","            new_row = pd.DataFrame({\n","                'Candidate Name': [candidate_name], \n","                'Job Category': [category], \n","                'Match Score': [score],\n","                'Experience': [experience]  # Add experience to each row\n","            })\n","            summary_table = pd.concat([summary_table, new_row], ignore_index=True)\n","    \n","    return summary_table\n","\n","# Assuming the necessary variables (clf, word_vectorizer, le) are defined elsewhere in your code.\n","resume_paths = glob.glob('./Resumes/*.docx')\n","result_table = process_resumes(resume_paths, clf, word_vectorizer, le, threshold=0.1)\n","csv_file = \"data\\\\resume_classification_results.csv\"\n","\n","# Save the DataFrame to a CSV file\n","result_table.to_csv(csv_file, index=False)\n","\n","print(result_table)\n","print(f\"Results saved to {csv_file}.\")\n","\n"]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Available job categories:\n","- Advocate\n","- Arts\n","- Automation Testing\n","- Blockchain\n","- Business Analyst\n","- Civil Engineer\n","- Data Science\n","- Database\n","- DevOps Engineer\n","- DotNet Developer\n","- ETL Developer\n","- Electrical Engineering\n","- HR\n","- Hadoop\n","- Health and fitness\n","- Java Developer\n","- Mechanical Engineer\n","- Network Security Engineer\n","- Operations Manager\n","- PMO\n","- Python Developer\n","- SAP Developer\n","- Sales\n","- Testing\n","- Web Designing\n","Enter 'exit' to stop.\n","\n","                           Advocate                           \n","\n","+----------------+-------------+--------------------+\n","| Candidate Name | Match Score | Experience (Years) |\n","+----------------+-------------+--------------------+\n","| Alice Johnson  |    100.0    |         8          |\n","+----------------+-------------+--------------------+\n"]}],"source":["from tabulate import tabulate\n","\n","def print_results_by_category(df, le):\n","    # Print the list of available job categories only once at the beginning\n","    print(\"\\nAvailable job categories:\")\n","    for category in le.classes_:\n","        print(\"-\", category)\n","    print(\"Enter 'exit' to stop.\")\n","    \n","    while True:\n","        # Prompt user to specify the job category\n","        target_category = input(\"\\nEnter the job category you are interested in or 'exit' to stop: \")\n","        \n","        # Check for exit condition\n","        if target_category.lower() == 'exit':\n","            break\n","        \n","        if target_category not in le.classes_:\n","            print(\"Invalid job category. Please try again.\")\n","            continue\n","\n","        # Filter DataFrame for the chosen category\n","        category_df = df[df['Job Category'] == target_category]\n","        \n","        # Prepare data for tabulate\n","        headers = ['Candidate Name', 'Match Score', 'Experience (Years)']\n","        # Include the experience data in the listing\n","        data = category_df[['Candidate Name', 'Match Score', 'Experience']].values.tolist()\n","        \n","        # Calculate the width of the table\n","        table_width = sum(len(str(header)) for header in headers) + len(headers) * 3 + 10  # Adjust for spacing and column\n","        \n","        # Print table header with category name centered\n","        print(\"\\n\" + target_category.center(table_width) + \"\\n\")\n","        \n","        # Print table using tabulate\n","        if not data:\n","            print(f\"No candidates found for {target_category}.\")\n","        else:\n","            print(tabulate(data, headers=headers, tablefmt=\"pretty\"))\n","\n","# Assuming 'result_table' is your DataFrame and 'le' is your LabelEncoder\n","# Ensure your 'result_table' DataFrame now includes an 'Experience' column, as modified in your earlier request\n","print_results_by_category(result_table, le)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Total Scores of Top Candidates"]},{"cell_type":"code","execution_count":97,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["  Candidate Name  Total Score  Job Category\n","0       Jane Doe         60.0  Data Science\n","1  Alice Johnson         50.0      Advocate\n","2      Tim David         50.0  Data Science\n"]}],"source":["import pandas as pd\n","\n","candidates_df = pd.read_csv(\"data\\\\candidates.csv\")\n","resume_scores_df = pd.read_csv(\"data\\\\resume_classification_results.csv\")\n","\n","# Merge DataFrames on \"Candidate Name\"\n","merged_df = pd.merge(candidates_df, resume_scores_df, left_on='name', right_on='Candidate Name', how='inner')\n","\n","# Calculate total scores\n","merged_df['Total Score'] = merged_df['score'] + merged_df['Match Score']\n","\n","# Sort by \"Candidate Name\" and \"Total Score\" in descending order to ensure the highest score comes first\n","merged_df = merged_df.sort_values(by=['Candidate Name', 'Total Score'], ascending=[True, False])\n","\n","# Drop duplicates keeping the first entry (highest score) for each candidate\n","unique_candidates_df = merged_df.drop_duplicates(subset=['Candidate Name'], keep='first')\n","\n","# Sort candidates by total score in descending order\n","ranked_df = unique_candidates_df.sort_values(by='Total Score', ascending=False)\n","\n","# Adjust the total scores to be out of 100\n","ranked_df['Total Score'] = ranked_df['Total Score'] / 2\n","\n","# Select columns for the final DataFrame\n","final_df = ranked_df[['Candidate Name', 'Total Score', 'Job Category']]\n","\n","# Reset index to start ranking from 1\n","final_df.reset_index(drop=True, inplace=True)\n","\n","# Display the final DataFrame\n","print(final_df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"}},"nbformat":4,"nbformat_minor":4}
